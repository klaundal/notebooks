{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use satellite magnetometer measurements to make a geomagnetic model\n",
    "\n",
    "\n",
    "This is a notebook that produces a model of the Earth's magnetic field from magnetic field measurements taken by ESA's Swarm satellites. It is an attempt to do this in a way that is as simple as possible, but still gives good results. \n",
    "\n",
    "The model is based on a spherical harmonic representation of the magnetic field. That means that we must calculate the values of the spherical harmonic basis functions at the locations of the data, and at the locations where we want to evaluate the magnetic field. This is somewhat complicated (it includes for example, the calculation of Legendre functions), and the code for that is hidden in the sh module, which is imported below, along with other Python modules and scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from viresclient import SwarmRequest\n",
    "import global_plots # tool for plotting data on the globe\n",
    "import sh # tools for spherical harmonic analysis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set some parameters for our model, most importantly the truncation level. That is where we stop the, in principle, infinite sum over spherical harmonics. Increasing the truncation levels (N and M) gives a higher resolution model, but it takes longer to fit, and may require more data. You can also adjust the number of data points that we use to estimate the model, but there is of course a limit for how much data we have. Experiment with changing these parameters. How little data can you use and still get good results?\n",
    "\n",
    "The R parameters is just a scaling parameter, and it should not matter what value you choose as long as you use the same value when you estimte the model parameters and when you calculate model predictions. In geomagnetic modeling, it is traditionally set to 6371.2 km, which is roughly the average Earth radius. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_data = 500 # number of data points that I will extract\n",
    "N, M = 12, 12 # spherical harmonic degree and order\n",
    "R    = 6371.2e3 # the Earth radius in m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we download Swarm data. We use the viresclient python module to do that. Try experimenting with different time periods (Swarm data is available from 2014 and onward), and see if you can detect changes in the magnetic field. You can also experiment with filtering the data by other parameters. For example, it is common to use only data from geomagnetically quiet times to reduce the effect of solar wind-induced disturbances in the magnetic field. It is also common to only use data taken at the Earth's nightside to avoid magnetic disturbances associated with sunlight-induced currents in the ionosphere. \n",
    "\n",
    "I grab data only from Swarm A and B, even though there is a third satellite, Swarm C. This is because Swarm A and Swarm C fly side by side, and measure basically the same field (for our purposes). So including C doesn't give us more information. I also grab data only every 30 seconds, even though measurements are available at 1 s resolution. The reason for this is that two consecutive measurements are taken so close together (about 7.5 km, since the satellites move at 7.5 km/s) that they do essentially not contribute new information about the structure of the magnetic field at the resolutions we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/1] Processing:  100%|███████████████████████████████████████████████████████████████████████████████████████|  [ Elapsed: 00:03, Remaining: 00:00 ]\n",
      "      Downloading:  30%|██████████████████████▌                                                     |  [ Elapsed: 00:07, Remaining: 00:18 ] (11.469MB)"
     ]
    }
   ],
   "source": [
    "request = SwarmRequest()\n",
    "\n",
    "# choose data from swarm A and B - we skip C since it is flying right next to A\n",
    "request.set_collection('SW_OPER_MAGA_LR_1B', 'SW_OPER_MAGB_LR_1B')\n",
    "\n",
    "# choose vector magnetic measurements every 30 seconds + some auxiliary measurement that we will use for filtering\n",
    "# B_NEC means B (magnetic field) in the North East and Centre (radially inward) directions. \n",
    "request.set_products(measurements=['B_NEC'], auxiliaries=['Kp'], sampling_step='PT30S')\n",
    "\n",
    "# set filter\n",
    "pass\n",
    "\n",
    "# get data from January 2020:\n",
    "data = request.get_between('2020-01-01T00:00:00', '2020-02-01T00:00:00')\n",
    "\n",
    "# save the data as a pandas dataframe \n",
    "df = data.as_dataframe()\n",
    "\n",
    "print('We have {} data points'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a lot of data, but I'm not going to use everything. One reasons for this is that the data points are not uniformly distributed on the sphere. There is much more data per square km near the poles than near equator. If we don't do anything with this, our model will be more strongly determined by the measurements at the poles, and may not fit the field near the equator so well. We want a *global* model, so we have to fix it somehow. \n",
    "\n",
    "The reason that we have more data near the pole is that the satellites are in a polar orbit, and visit both poles every orbit (one orbit takes about 1.5 hour). On the other hand, they visit a specific place near the equator only once per day, since the orbital planes are roughly fixed with respect to the Sun, while the Earth rotates. To get an approximately uniform distribution of data points I choose a random subset using a specific weight function that depends on latitude. I plot two examples of subsets, with and without the weighting. \n",
    "\n",
    "Normally, we would not do it in exactly this way, but instead use a weighting function in the inversion step (see further down). But I think this method is more illustrative, and I want to keep the inversion as simple as possible.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.sin( (90 - df['Latitude']) * np.pi / 180)\n",
    "p = weight / np.sum(weight)\n",
    "\n",
    "indices = np.random.choice(np.arange(len(df)), N_data, replace = True, p = p) \n",
    "subset = df.iloc[indices] \n",
    "\n",
    "# plot the result\n",
    "global_plots.global_scatterplot(subset.Latitude, subset.Longitude, np.ones(len(subset)), vmax=1, vmin=0.2, title = 'Uniform distribution of data points')\n",
    "\n",
    "# just to illustrate, see what happens if we don't use the weighting:\n",
    "indices = np.random.choice(np.arange(len(df)), N_data, replace = True) \n",
    "_ = df.iloc[indices] \n",
    "global_plots.global_scatterplot(_.Latitude, _.Longitude, np.ones(len(subset)), vmax=1, vmin=0.2, title = 'Unweighted')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our dataset, and can set up the system of equations that relate Gauss coefficients (scaling factors in the spherical harmonic expansion) to the data. In the three lines below, we calculate $G$, $d$ and $m$ in the matrix equation \n",
    "\n",
    "$Gm = d$\n",
    "\n",
    "Here, $m$ is a vector that contains the (K) Gauss coefficients (the scaling factors in the spherical harmonic representation of the magnetic field). $d$ is a vector that contains all the measured magnetic field components. It is 3 times N_data long, and composed of first the northward magnetic field components, then the eastward components, and then the components of the field that point radially inward. The $G$ matrix is a 3N_data $\\times$ K matrix that relates the data points to the Gauss coefficients using the equations for spherical harmonics.\n",
    "\n",
    "The $m$ vector, the solution vector, is found my minimizing the squared error. That is what the np.linalg.lstsq function does. So we use a least squares method, which should be familiar. There are of course more advanced ways to do this, but it works. \n",
    "\n",
    "Once we have the solution vector, I extract the coefficients that correspond to cos terms (I call those coefficients g) and sin terms (called h). I also extract the three coefficients that corresponds to the dipole part of the field. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are ready to set up the system of equations (this gets complicated):\n",
    "G, cos_keys, sin_keys = sh.get_G(subset['Radius'].values, subset['Latitude'].values, subset['Longitude'].values, N, M)\n",
    "\n",
    "d = np.hstack(np.vstack(subset['B_NEC'].values).T)\n",
    "\n",
    "# now we fit the cofficents\n",
    "m = np.linalg.lstsq(G, d, rcond = 0)[0]\n",
    "\n",
    "# the G matrix is organized with the cos coefficients (g) first and then the sin coefficients (h):\n",
    "g = m[: len(cos_keys)]\n",
    "h = m[len(cos_keys) :]\n",
    "\n",
    "# get the dipole coefficients;\n",
    "g10, g11 = g[:2]\n",
    "h11 = h[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the misfit (difference between data and our model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the misfit as function of latitude:\n",
    "dm = G.dot(m) # model predictions\n",
    "error = dm - d\n",
    "err_n, err_e, err_c = np.split(error, 3)\n",
    "fig, ax = plt.subplots(figsize = (15, 8))\n",
    "ax.scatter(subset['Latitude'].values, err_n, label = 'North')\n",
    "ax.scatter(subset['Latitude'].values, err_e, label = 'East')\n",
    "ax.scatter(subset['Latitude'].values, err_c, label = 'Center')\n",
    "ax.legend(frameon = False)\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Misfit [nT]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then a plot of the model predictions of the radial magnetic field component, evaluated on a global grid. Compare this to a scatter plot of the data points that we used to make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = np.meshgrid(np.linspace(-89.9, 89.9, 90), np.linspace(0, 360, 190)) # grid for plotting\n",
    "G_grid, _, __ = sh.get_G(np.full(lat.size, R), lat.flatten(), lon.flatten(), N, M)\n",
    "BC_model = np.split(G_grid.dot(m), 3)[2]\n",
    "\n",
    "global_plots.global_contour(lat.flatten(), lon.flatten(), BC_model, vmin = -60000, vmax = 60000)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to data values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_plots.global_scatterplot(subset.Latitude, subset.Longitude, np.split(d, 3)[2], vmax=60000, vmin=-60000) # Br\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print the dipole pole locations, and dipole coefficients. We can compare our dipole model to the International Geomagnetic Reference Field (IGRF) model, which is a much used model of the Earth's magnetic field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B0 = np.sqrt(g10**2 + g11**2 + h11**2)\n",
    "pole_lat, pole_lon = 90 - np.arccos(-g10/B0) / np.pi * 180, np.arctan2(-h11, -g11) / np.pi * 180\n",
    "print('The location of my dipole pole is {:.2f} degrees north, {:.2f} degrees east'.format(pole_lat, pole_lon))\n",
    "print('g10 = {:.1f}, g11  = {:.1f}, h11 = {:.1f}'.format(g10, g11, h11))\n",
    "print('The corresponding IGRF 2020 coefficients are -29404.8, -1450.9, and 4652.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and print the magnetic declination at various points \n",
    "\n",
    "Note: Here we treat the Earth as spherical. Usually when you see coordinates of a place on Earth, it refers to a *geodetic* system, which means that the ellipsoidal shape of the planet is taken into account. So If you insert those coordinates in the code below, you will be slightly off where you want to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.array([55.5, 73])\n",
    "lons = np.array([20.0, 30])\n",
    "\n",
    "G_points, _, __ = sh.get_G(np.full(lats.size, R), lats, lons, N, M)\n",
    "BN, BE, BC = np.split(G_points.dot(m), 3)\n",
    "\n",
    "for i in range(len(lats)):\n",
    "    declination = np.arctan(BE[i]/BN[i]) * 180 / np.pi\n",
    "    print('The magnetic declination at ({:.1f} N, {:.1f} E) is {:.2f} degrees'.format(lats[i], lons[i], declination))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
